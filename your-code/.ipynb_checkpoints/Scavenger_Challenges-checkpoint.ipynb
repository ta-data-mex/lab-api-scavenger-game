{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Fork Languages\n",
    "\n",
    "You will find out how many programming languages are used among all the forks created from the main lab repo of your bootcamp. Assuming the main lab repo is `ironhack-datalabs/madrid-oct-2018`, you will:\n",
    "\n",
    "1. Obtain the full list of forks created from the main lab repo via Github API.\n",
    "\n",
    "1. Loop the JSON response to find out the `language` attribute of each fork. Use an array to store the `language` attributes of each fork.\n",
    "    * *Hint: Each language should appear only once in your array.*\n",
    "    \n",
    "\n",
    "1. Print the language array. It should be something like:\n",
    "\n",
    "    `[\"Python\", \"Jupyter Notebook\", \"HTML\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "ironhack = requests.get('https://api.github.com/repos/ironhack-datalabs/madrid-oct-2018', verify = False).json()\n",
    "forks = requests.get(ironhack['forks_url'], verify = False).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://api.github.com/repos/aiborra11/mad-oct-2018',\n",
       " 'https://api.github.com/repos/lmartinezruizit/datamad0119',\n",
       " 'https://api.github.com/repos/eye8/madrid-oct-2018',\n",
       " 'https://api.github.com/repos/ArieHassan/madrid-oct-2018',\n",
       " 'https://api.github.com/repos/cmvalma/madrid-oct-2018',\n",
       " 'https://api.github.com/repos/criraca/madrid-oct-2018',\n",
       " 'https://api.github.com/repos/boyander/madrid-oct-2018',\n",
       " 'https://api.github.com/repos/AlbertoCastellanos/madrid-oct-2018',\n",
       " 'https://api.github.com/repos/elenajpp/madrid-oct-2018',\n",
       " 'https://api.github.com/repos/pablobarrio/madrid-oct-2018',\n",
       " 'https://api.github.com/repos/miriammg/madrid-oct-2018',\n",
       " 'https://api.github.com/repos/albertogcmr/madrid-oct-2018',\n",
       " 'https://api.github.com/repos/marisfont/madrid-oct-2018']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of forks\n",
    "[fork['url'] for fork in forks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HTML', 'Jupyter Notebook', 'Python'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of languages\n",
    "set([fork['language'] for fork in forks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Count Commits\n",
    "\n",
    "Count how many commits were made in the past week.\n",
    "\n",
    "1. Obtain all the commits made in the past week via API, which is a JSON array that contains multiple commit objects.\n",
    "\n",
    "1. Count how many commit objects are contained in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits = requests.get(ironhack['commits_url'][:-6], verify = False).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fix',\n",
       " 'remove bonus challenge 2',\n",
       " 'Parallelization lab',\n",
       " 'error handling lab',\n",
       " 'fix readme',\n",
       " 'fixing Q1-Q3',\n",
       " 'functional programming lab',\n",
       " 'placeholder for lab adv web scraping and code simplicity',\n",
       " \"Merge branch 'master' of https://github.com/ironhack-labs/data-labs\",\n",
       " 'minor updates',\n",
       " 'string ops lab',\n",
       " 'lambda lab',\n",
       " 'fix initial description',\n",
       " 'oop lab main',\n",
       " \"Merge branch 'master' of https://github.com/ironhack-labs/data-labs\",\n",
       " 'lab-tuple-set-dict',\n",
       " 'Updating Getting Started section',\n",
       " 'Adding snippet about Jupyter Notebook',\n",
       " 'Update main.ipynb',\n",
       " 'RSS lab to master branch',\n",
       " 'adding .gitkeep for lab-rss',\n",
       " 'remove solution files from all labs; pls add solutions to branch lab-solutions',\n",
       " 'Setup for RSS lab',\n",
       " 'advanced mysql lab',\n",
       " 'mysql-select references',\n",
       " \"Merge branch 'master' of https://github.com/ironhack-labs/data-labs\",\n",
       " 'lab-mysql-select',\n",
       " \"Merge branch 'master' of https://github.com/ironhack-labs/data-labs\",\n",
       " 'map reduce filter lab',\n",
       " \"Merge branch 'master' of https://github.com/ironhack-labs/data-labs\"]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain all the commits made in the past week via API, which is a JSON array that contains multiple commit objects\n",
    "# All dates of the commits are much further back than last week, thus all commits are shown\n",
    "[commit['commit']['message'] for commit in commits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many commit objects are contained in the array\n",
    "len([commit['commit']['message'] for commit in commits])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Hidden Cold Joke\n",
    "\n",
    "Using Python, call Github API to find out the cold joke contained in the 24 secret files in the following repo:\n",
    "\n",
    "https://github.com/ironhack-datalabs/scavenger\n",
    "\n",
    "The filenames of the secret files contain `.scavengerhunt` and they are scattered in different directories of this repo. The secret files are named from `.0001.scavengerhunt` to `.0024.scavengerhunt`. They are scattered randomly throughout this repo. You need to **search for these files by calling the Github API**, not searching the local files on your computer.\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Github API documentation can be found [here](https://developer.github.com/v3/).\n",
    "\n",
    "* You will need to study the Github API documentation to decide which API endpoint to call and what parameters to use in order to obtain the information you need. Unless you are already super familiar with Github API or super lucky, you probably will do some trials and errors. Therefore, be prepared to go back and forth in studying the API documentation, testing, and revising until you obtain what you need.\n",
    "\n",
    "* After receiving the JSON data object, you need to inspect its structure and decide how to parse the data.\n",
    "\n",
    "* When you test your requests with Github API, sometimes you may be blocked by Github with an error message that reads:\n",
    "\n",
    "\t> You have triggered an abuse detection mechanism and have been temporarily blocked from content creation. Please retry your request again later.\n",
    "\n",
    "\tDon't worry. Check the parameters in your request and wait for a minute or two before you make additional requests.\n",
    "\n",
    "**After you find out the secrete files:**\n",
    "\n",
    "1. Sort the filenames ascendingly.\n",
    "\n",
    "1. Read the content of each secret files into an array of strings.\n",
    "\n",
    "1. Concatenate the strings in the array separating each two with a whitespace.\n",
    "\n",
    "1. Print out the joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "joke = []\n",
    "for content in requests.get(requests.get('https://api.github.com/repos/ironhack-datalabs/scavenger',verify=False).json()['contents_url'][:-7],verify=False).json():\n",
    "    for file in requests.get(content['url'], verify = False).json():\n",
    "        if type(file) == str:\n",
    "            pass\n",
    "        elif 'scavengerhunt' in file['name']:\n",
    "            names.append(file['name'])\n",
    "            joke.append(base64.b64decode(requests.get(file['url'], verify = False).json()['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.0001.scavengerhunt',\n",
       " '.0002.scavengerhunt',\n",
       " '.0003.scavengerhunt',\n",
       " '.0004.scavengerhunt',\n",
       " '.0005.scavengerhunt',\n",
       " '.0006.scavengerhunt',\n",
       " '.0007.scavengerhunt',\n",
       " '.0008.scavengerhunt',\n",
       " '.0009.scavengerhunt',\n",
       " '.0010.scavengerhunt',\n",
       " '.0011.scavengerhunt',\n",
       " '.0012.scavengerhunt',\n",
       " '.0013.scavengerhunt',\n",
       " '.0014.scavengerhunt',\n",
       " '.0015.scavengerhunt',\n",
       " '.0016.scavengerhunt',\n",
       " '.0017.scavengerhunt',\n",
       " '.0018.scavengerhunt',\n",
       " '.0019.scavengerhunt',\n",
       " '.0020.scavengerhunt',\n",
       " '.0021.scavengerhunt',\n",
       " '.0022.scavengerhunt',\n",
       " '.0023.scavengerhunt',\n",
       " '.0024.scavengerhunt']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the filenames ascendingly\n",
    "sorted(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In data science, 80 percent of time spent is preparing data, 20 percent of time is spent complaining about the need to prepare data.'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the content of each secret files into an array of strings.\n",
    "' '.join([i[1].decode('utf-8').replace('\\n','') for i in sorted(list(zip(names, joke)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
